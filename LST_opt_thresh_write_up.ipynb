{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Determination of Optimal Initial Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. INTRODUCTION\n",
    "            \n",
    "    Using lesion probability maps created from LST’s Lesion Growth Algorithm (LGA) helps to automate the process of mapping out the lesions visible in our MS subjects’ MRI Images. Unfortunately these lesion probability maps require time-consuming manual edits to correct the False Positives and False Negative. To minimize this issue we created a script to run LST multiple times while iterating through all possible parameters, bin threshold and initial threshold, and created a new metric to evaluate which parameters create the most accurate lesion probability map for any given FLAIR-T1 image pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. METHODS\n",
    " \n",
    "### A. \n",
    "    Our first step in this experiment required writing a script to run LST’s provided tool for determining the optimum threshold on a given lesion probability map, while iterating through its one parameter, binary threshold while keeping initial threshold the same. (0.3) The scripts are displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.spm.base import SPMCommand, SPMCommandInputSpec\n",
    "from nipype.interfaces.base import (BaseInterface, TraitedSpec, traits, File,\n",
    "                                    OutputMultiPath, BaseInterfaceInputSpec,\n",
    "                                    isdefined, InputMultiPath)\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.io as nio\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "import os\n",
    "#from utils import doit_workflow\n",
    "\n",
    "\n",
    "class DoitInputSpec(SPMCommandInputSpec):\n",
    "    data_ref = traits.List(File(exists=True), field=\"doit.data_ref\")\n",
    "    bin_thresh = traits.Any(0.5, field=\"doit.bin_thresh\", usedefault=True) #default is 0.5\n",
    "\n",
    "\n",
    "class DoitOutputSpec(TraitedSpec):\n",
    "    csv_file = OutputMultiPath(File(exists=True))\n",
    "\n",
    "\n",
    "class Doit(SPMCommand):\n",
    "    input_spec = DoitInputSpec\n",
    "    output_spec = DoitOutputSpec\n",
    "    _jobtype = 'tools'\n",
    "    _jobname = 'LST'\n",
    "\n",
    "    def _make_matlab_command(self, contents, postscript=None):\n",
    "        len_ref = len(self.inputs.data_ref)\n",
    "\n",
    "        contents = \"\"\"\n",
    "        %% Generated by nipype.interfaces.spm\n",
    "        if isempty(which('spm')),\n",
    "             throw(MException('SPMCheck:NotFound', 'SPM not in matlab path'));\n",
    "        end\n",
    "        [name, version] = spm('ver');\n",
    "        fprintf('SPM version: %s Release: %s',name, version);\n",
    "        fprintf('SPM path: %s', which('spm'));\n",
    "        spm('Defaults','fMRI');\n",
    "\n",
    "        if strcmp(name, 'SPM8') || strcmp(name(1:5), 'SPM12'),\n",
    "           spm_jobman('initcfg');\n",
    "           spm_get_defaults('cmdline', 1);\n",
    "        end\n",
    "        \"\"\"\n",
    "\n",
    "        contents += \"\"\"\n",
    "        jobs{1}.spm.tools.LST.doit.bin_thresh = %f;\n",
    "        \"\"\" % self.inputs.bin_thresh\n",
    "\n",
    "        for i, ref in enumerate(self.inputs.data_ref):\n",
    "            contents += \"\"\"\n",
    "            jobs{1}.spm.tools.LST.doit.data_ref{%d, 1} = '%s';\n",
    "        \"\"\" % (i+1,\n",
    "               ref)\n",
    "\n",
    "        contents += \"\"\"\n",
    "                    spm_jobman('run', jobs);\n",
    "                    \"\"\"\n",
    "        return contents\n",
    "\n",
    "    def _format_arg(self, opt, spec, val):\n",
    "        \"\"\"Convert input to appropriate format for spm\n",
    "        \"\"\"\n",
    "        # import numpy as np\n",
    "        # from nipype.utils.filemanip import copyfiles\n",
    "\n",
    "        # if opt in ['t1_files', 'flair_files']:\n",
    "        #    val2 = copyfiles(val, os.path.abspath(\".\"))\n",
    "        #    return np.array(val2, dtype=object)\n",
    "        print(\"_format_arg opt is: \", opt)\n",
    "        print(\"_format_arg opt is: \", spec)\n",
    "        print(\"_format_arg opt is: \", val)\n",
    "\n",
    "        # TODO change the format of data_ref\n",
    "\n",
    "        return super(Doit, self)._format_arg(opt, spec, val)\n",
    "\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        #from nipype.utils.filemanip import fname_presuffix\n",
    "        from glob import glob\n",
    "        from os.path import join\n",
    "        outputs = self._outputs().get()\n",
    "        print(\"Listing outputs!\")\n",
    "        print(os.path.abspath('.'))\n",
    "\n",
    "        outputs[\"csv_file\"] = glob(join(os.path.abspath('.'), \"LST_doit_*.csv\"))\n",
    "        print(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Three python files were written in the same directory. The script above wraps SPM command into python to run LGA. The file name is doit_spm.py__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'sf713420'\n",
    "\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.io as nio\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "import os\n",
    "import sys\n",
    "print(__file__)\n",
    "print(sys.path)\n",
    "sys.path.append(os.path.dirname(__file__))\n",
    "import numpy as np\n",
    "from doit_spm import Doit\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def doit_workflow(data_ref, bin_thresh, base_dir = None, sink_dir = None):\n",
    "    # data_ref should be a list of pathname\n",
    "    # base_dir is the working directory\n",
    "    # sink_dir is where the data is sinking\n",
    "    if base_dir is None:\n",
    "        base_dir = os.getcwd()\n",
    "        print(\"base_dir is: \", base_dir)\n",
    "    if sink_dir is None:\n",
    "        sink_dir = base_dir\n",
    "        print(\"sink_dir is: \", sink_dir)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "\n",
    "    # inputs\n",
    "    inputspec = pe.Node(IdentityInterface(fields = ['data_ref', 'thresh']), name = 'inputspec')\n",
    "    inputspec.inputs.mandatory_inputs = True\n",
    "    inputspec.inputs.data_ref = data_ref\n",
    "    inputspec.inputs.thresh = bin_thresh\n",
    "\n",
    "\n",
    "    # doit_node\n",
    "    doit_node = pe.Node(name = 'doit_node',\n",
    "                           interface = Doit(),\n",
    "                           #iterfield = ['data_ref']\n",
    "                           )\n",
    "    doit_node.iterables = (\"bin_thresh\", bin_thresh)\n",
    "    # TODO\n",
    "    print(doit_node.iterables)\n",
    "    print(doit_node.inputs.bin_thresh)\n",
    "\n",
    "    #datasink\n",
    "    data_sink = pe.Node(nio.DataSink(), name = 'sinker')\n",
    "    data_sink.inputs.base_directory = sink_dir\n",
    "    data_sink.inputs.container = '.'\n",
    "\n",
    "    # Pipeline assembly\n",
    "    pipeline = pe.Workflow(name = 'pipeline_doit')\n",
    "    pipeline.base_dir = base_dir\n",
    "\n",
    "    pipeline.connect(inputspec, 'data_ref', doit_node, 'data_ref')\n",
    "    pipeline.connect(inputspec, 'thresh', doit_node, 'bin_thresh')\n",
    "    pipeline.connect(doit_node, 'csv_file', data_sink, '@LST_doit')\n",
    "\n",
    "    pipeline.write_graph(graph2use = 'orig')\n",
    "    pipeline.config['Execution'] = {'keep_inputs': True, 'remove_unnecessary_outputs': False}\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A nipype workflow was made to iterate through binary threshold with increment 0.05. The file name is utils.py__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'sf713420'\n",
    "\n",
    "import os\n",
    "from nipype.interfaces.base import isdefined\n",
    "from utils import doit_workflow, flatten\n",
    "import sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Reading file from the path: \", sys.argv[1], \"\\n\")\n",
    "    data_ref = glob(sys.argv[1])\n",
    "\n",
    "    FLAIR_T1_name = data_ref[0].split('/')[5]\n",
    "    output_dir = '/data/henry1/tristan/LST/opt_thresh_results'\n",
    "    sk_dir = os.path.join(output_dir,\n",
    "                          FLAIR_T1_name\n",
    "                          )\n",
    "\n",
    "    dwf = doit_workflow(data_ref, thresh_array, sink_dir=sk_dir)\n",
    "    dwf.run()\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(os.path.join(sk_dir, '_bin_thresh_' + thresh_array[i]), newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "\n",
    "    csvfile.close()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This script takes the first positional argument as filename for running the LGA DC calculation workflow. The script is name as doit_arg.py__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The csv files are generated for each binary threshold. All of them includes 102 mses which are FLAIR-MPRAGE image pairs. The average Dice Coefficient (DC), Sensitivity (SE) and Specificity (SP) among these mses were calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. \n",
    "    The next step a script that would run LST’s LGA on a given FLAIR-T1 image pair while iterating through its one parameter, initial threshold was run. The multiple lesion probability maps created would then be analyzed using LST’s provided tool for determining the optimum threshold to evaluate which initial threshold will create a map that requires the least amount of manual edits. The LGA iteration for initial threshold (kappa) increment of 0.05 was run in PBR. 5 test mses (mse3727, mse4413, mse4482, mse4739, mse4754) were run and outputs were calculated using previous code with binary threshold set to 0.3. The code is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'sf713420'\n",
    "from nipype.interfaces.base import (BaseInterface, TraitedSpec, traits, File,\n",
    "                                    OutputMultiPath, BaseInterfaceInputSpec,\n",
    "                                    isdefined, InputMultiPath)\n",
    "\n",
    "from ...config import config\n",
    "from glob import glob\n",
    "import os\n",
    "from ...base import register_workflow, PBRBaseInputSpec, PBRBaseInterface\n",
    "from nipype.interfaces.spm.base import SPMCommand, SPMCommandInputSpec\n",
    "\n",
    "class LGAInputSpec(SPMCommandInputSpec):\n",
    "    t1_files = traits.List(File(exists=True), field=\"lga.data_T1\")\n",
    "    flair_files = traits.List(File(exists=True), field=\"lga.data_F2\")\n",
    "    kappa = traits.Float(0.3, field=\"lga.opts_lga.initial\", usedefault=True)\n",
    "    maxiter = traits.Int(50, field=\"lga.opts_lga.maxiter\", usedefault=True)\n",
    "    phi = traits.Float(1.0, field=\"lga.opts_lga.mrf\", usedefault=True)\n",
    "    html_report = traits.Bool(0, field=\"lga.html_report\", usedefault=True)\n",
    "\n",
    "class LGAOutputSpec(TraitedSpec):\n",
    "    lesion_probability_map = OutputMultiPath(File(exists=True))\n",
    "    mat_file = OutputMultiPath(File(exists=True))\n",
    "    bias_corrected_flair = OutputMultiPath(File(exists=True))\n",
    "\n",
    "\n",
    "class LGA(SPMCommand):\n",
    "    input_spec = LGAInputSpec\n",
    "    output_spec = LGAOutputSpec\n",
    "    _jobtype = 'tools'\n",
    "    _jobname = 'LST'\n",
    "\n",
    "    def _format_arg(self, opt, spec, val):\n",
    "        \"\"\"Convert input to appropriate format for spm\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from nipype.utils.filemanip import copyfiles\n",
    "\n",
    "        if opt in ['t1_files', 'flair_files']:\n",
    "            val2 = copyfiles(val, os.path.abspath(\".\"))\n",
    "            return np.array(val2, dtype=object)\n",
    "\n",
    "        return super(LGA, self)._format_arg(opt, spec, val)\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        from nipype.utils.filemanip import fname_presuffix\n",
    "        outputs = self._outputs().get()\n",
    "        kappa = round(self.inputs.kappa, 2)\n",
    "\n",
    "        if str(kappa) == '1.0':\n",
    "            kappa = 1\n",
    "\n",
    "        outputs[\"lesion_probability_map\"] = [fname_presuffix(f,\n",
    "                                                prefix=\"ples_lga_{}_rm\".format(kappa),\n",
    "                                                newpath=os.path.abspath(\".\")) for f in self.inputs.flair_files]\n",
    "        outputs[\"bias_corrected_flair\"] = [fname_presuffix(f,\n",
    "                                                prefix=\"rm\",\n",
    "                                                newpath=os.path.abspath(\".\")) for f in self.inputs.flair_files]\n",
    "        outputs[\"mat_file\"] = [fname_presuffix(f,\n",
    "                                                prefix=\"LST_lga_rm\",\n",
    "                                                newpath=os.path.abspath(\".\"),\n",
    "                                                use_ext=False)+\".mat\"  for f in self.inputs.flair_files]\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def mapper(Nt1, t1):\n",
    "    return [t1[Nt1]]\n",
    "\n",
    "def mapper2(Nt2, t2):\n",
    "    return [t2[Nt2]]\n",
    "\n",
    "\n",
    "class LGAIterInputSpec(PBRBaseInputSpec):\n",
    "    t1_files = InputMultiPath(File(exists=True))\n",
    "    flair_files = InputMultiPath(File(exists=True))\n",
    "\n",
    "class LGAIterOutputSpec(TraitedSpec):\n",
    "    lesion_probability_mask_lga = OutputMultiPath(File(exists=True))\n",
    "    lesion_binary_ref = OutputMultiPath(File(exists=True))\n",
    "    lga_mat = OutputMultiPath(File(exists=True))\n",
    "    lga_txt = OutputMultiPath(File(exists=True))\n",
    "    lga_index = OutputMultiPath(File(exists=True))\n",
    "    lga_metrics = OutputMultiPath(traits.Dict())\n",
    "\n",
    "class LGAIter(PBRBaseInterface):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    input_spec = LGAIterInputSpec\n",
    "    output_spec = LGAIterOutputSpec\n",
    "    flag = \"lga\" #this is for pbr mse# -w interfacename\n",
    "    connections = [(\"align\", \"t1_files\", \"t1_files\"),\n",
    "                   (\"align\", \"flair_files\", \"flair_files\")]\n",
    "\n",
    "    def _run_interface_pbr(self, runtime):\n",
    "        from nipype.pipeline.engine import Node, Workflow, MapNode\n",
    "        from nipype.interfaces.io import DataSink\n",
    "        import nipype.algorithms.misc as misc\n",
    "        from nipype.interfaces.utility import IdentityInterface, Function\n",
    "        import numpy as np\n",
    "\n",
    "        wf = Workflow(name=\"lga_%s\"%self.inputs.mseID)\n",
    "        wf.base_dir = os.path.join(config[\"working_directory\"])\n",
    "\n",
    "        #get_ratio_workflow(config)\n",
    "        inputspec = Node(IdentityInterface([\"t1s\", \"flairs\"]), name=\"inputspec\")\n",
    "        #wf.get_node(\"inputspec\")\n",
    "        #inputspec.inputs.examID = self.inputs.mseID\n",
    "\n",
    "        map_func = Node(Function(input_names=[\"Nt1\", \"t1\"],\n",
    "                                 output_names=[\"t1\"],\n",
    "                                 function=mapper),\n",
    "                        name=\"stupid_mapper\")\n",
    "\n",
    "        map_func2 = Node(Function(input_names=[\"Nt2\", \"t2\"],\n",
    "                                 output_names=[\"t2\"],\n",
    "                                 function=mapper2),\n",
    "                        name=\"stupid_mapper2\")\n",
    "\n",
    "        map_func.inputs.t1 = self.inputs.t1_files\n",
    "        map_func2.inputs.t2 = self.inputs.flair_files\n",
    "\n",
    "        map_func.iterables = [('Nt1', range(len(self.inputs.t1_files)))]\n",
    "        map_func2.iterables = [('Nt2', range(len(self.inputs.flair_files)))]\n",
    "\n",
    "        wf.connect(map_func, \"t1\", inputspec, \"t1s\")\n",
    "        wf.connect(map_func2, \"t2\", inputspec, \"flairs\")\n",
    "\n",
    "        gunzip_t1 = MapNode(interface=misc.Gunzip(), name='gunzip_t1', iterfield=[\"in_file\"])\n",
    "        gunzip_flair = MapNode(interface=misc.Gunzip(), name='gunzip_flair', iterfield=[\"in_file\"])\n",
    "        wf.connect(inputspec, \"t1s\", gunzip_t1, \"in_file\")\n",
    "        wf.connect(inputspec, \"flairs\", gunzip_flair, \"in_file\")\n",
    "\n",
    "        lga = Node(LGA(), name=\"lga\")\n",
    "        init_thresh = np.linspace(0.05, 1.00, num=20)\n",
    "        lga.iterables = (\"kappa\", init_thresh)\n",
    "        # or lga.inputs.kappa = init_thresh (?)\n",
    "        wf.connect(gunzip_t1, \"out_file\", lga, \"t1_files\")\n",
    "        wf.connect(gunzip_flair, \"out_file\", lga, \"flair_files\")\n",
    "\n",
    "        sinker = Node(DataSink(), name=\"sinker\")\n",
    "        sinker.inputs.base_directory = config[\"output_directory\"]\n",
    "        sinker.inputs.container = self.inputs.mseID\n",
    "\n",
    "        import nipype.interfaces.fsl as fsl\n",
    "        cluster_lga = MapNode(fsl.Cluster(threshold=0.0001,\n",
    "                                          out_index_file = True,\n",
    "                                          #out_localmax_txt_file=True,\n",
    "                                          use_mm=True),\n",
    "                              name=\"cluster_lga\",\n",
    "                              iterfield=[\"in_file\"])\n",
    "        wf.connect(lga, \"lesion_probability_map\", cluster_lga, \"in_file\")\n",
    "        wf.connect(cluster_lga, \"index_file\", sinker, \"lst.lga.cluster\")\n",
    "\n",
    "        from nipype.interfaces.freesurfer import SegStats\n",
    "        segstats_lga = MapNode(SegStats(), name=\"segstats_lga\", iterfield=[\"segmentation_file\"])\n",
    "        wf.connect(cluster_lga, \"index_file\", segstats_lga, \"segmentation_file\")\n",
    "\n",
    "        wf.connect(segstats_lga, \"summary_file\", sinker, \"lst.lga.@summaryfile\")\n",
    "\n",
    "        def getsubs(t1,t2):\n",
    "            # Make substitutions\n",
    "            subs = [(\"_Nt1_%d/_Nt2_%d/_segstats_lga0/summary.stats\"%(i,j),\n",
    "                     \"{}/{}_summary.stats\".format(t1[i].split(\"/\")[-1].split(\".nii.gz\")[0],\n",
    "                                     t2[j].split(\"/\")[-1].split(\".nii.gz\")[0])) \\\n",
    "                     for i in range(len(t1)) for j in range(len(t2))]\n",
    "            subs += [(\"_Nt1_%d/_Nt2_%d\"%(i,j),t1[i].split(\"/\")[-1].split(\".nii.gz\")[0]) for i in range(len(t1)) for j in range(len(t2))]\n",
    "            subs += [(\"_Nt2_%d\"%i, \"\") for i in range(10)]\n",
    "            subs += [(\"_cluster_lga0\", \"\")]\n",
    "            return subs\n",
    "\n",
    "        subs = Node(Function(input_names=[\"t1\", \"t2\"],\n",
    "                             output_names=[\"subs\"],\n",
    "                             function=getsubs),\n",
    "                    name=\"subs\")\n",
    "        #sinker.inputs.substitutions = getsubs()\n",
    "        wf.connect(map_func, \"t1\", subs, \"t1\")\n",
    "        wf.connect(map_func2, \"t2\", subs, \"t2\")\n",
    "        wf.connect(subs, \"subs\", sinker, \"substitutions\")\n",
    "        wf.connect(lga, \"lesion_probability_map\", sinker, \"lst.lga.@map\")\n",
    "        wf.connect(lga, \"mat_file\", sinker, \"lst.lga.@mat\")\n",
    "\n",
    "        wf.config = {\"execution\": {\"crashdump_dir\": os.path.join(config[\"crash_directory\"],\n",
    "                                                                 self.inputs.mseID,\n",
    "                                                                 self.flag)}}\n",
    "        wf.run(plugin=self.inputs.plugin,\n",
    "               plugin_args=self.inputs.plugin_args)\n",
    "\n",
    "        return runtime\n",
    "\n",
    "\n",
    "    def _get_output_folder(self):\n",
    "        # output folder for status.json\n",
    "        return \"lst/lga\"\n",
    "\n",
    "    def get_metrics(self, f):\n",
    "        import numpy as np\n",
    "        if os.path.exists(f):\n",
    "            foo = np.genfromtxt(f)\n",
    "            print(\"foo.shape is\", foo.shape)\n",
    "            if len(foo.shape)==2:\n",
    "                data = foo[:,3][1:]\n",
    "                output = {\"number_of_lesions\": data.shape[0],\n",
    "                          \"total_lesion_volume\": np.sum(data),\n",
    "                          \"max_lesion_size\": np.max(data)}\n",
    "                return output\n",
    "            else:\n",
    "                return {\"number_of_lesions\": 0}\n",
    "        else:\n",
    "            raise FileNotFoundError\n",
    "\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        # managing outputs for later calculate Dice Coefficient\n",
    "        import shutil  # copy2 also copy file metadata like file's creation and modification times\n",
    "        import numpy as np\n",
    "        from glob import glob\n",
    "\n",
    "        bin_map_dir = \"/data/henry1/tristan/LST/FLAIR-MPRAGE\" # TODO make a dictionary\n",
    "        bin_map = \"*-{0}*_bin_lesion_map.nii\".format(self.inputs.mseID)\n",
    "        src = ''.join(glob(os.path.join(bin_map_dir, self.inputs.mseID, bin_map)))\n",
    "        dstnames = glob(os.path.join(config[\"output_directory\"], self.inputs.mseID,\n",
    "                                     \"lst\", \"lga\", \"*\", \"_kappa_*\"))\n",
    "        for dst in dstnames:\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "        outputs = self._outputs().get()\n",
    "\n",
    "        outputs[\"lesion_probability_mask_lga\"] = sorted(glob(os.path.join(config[\"output_directory\"],\n",
    "                                                   self.inputs.mseID, \"lst\",\"lga\",\"*\",\n",
    "                                                   \"_kappa_*\", \"ples_lga*.nii\")))\n",
    "        outputs[\"lesion_binary_ref\"] = sorted(glob(os.path.join(config[\"output_directory\"], self.inputs.mseID,\n",
    "                                                                \"lst\", \"lga\", \"*\", \"_kappa_*\", bin_map)))\n",
    "        outputs[\"lga_mat\"] = sorted(glob(os.path.join(config[\"output_directory\"],\n",
    "                                                   self.inputs.mseID, \"lst\",\"lga\",\"*\",\n",
    "                                                   \"_kappa_*\", \"*.mat\")))\n",
    "        outputs[\"lga_txt\"] = sorted(glob(os.path.join(config[\"output_directory\"],\n",
    "                                                   self.inputs.mseID, \"lst\",\"lga\",\"*\",\n",
    "                                                   \"_kappa_*\", \"_segstats_lga0\", \"*.stats\")))\n",
    "        outputs[\"lga_index\"] = sorted(glob(os.path.join(config[\"output_directory\"],\n",
    "                                                   self.inputs.mseID, \"lst\",\"lga\",\"*\",\n",
    "                                                   \"_kappa_*\", \"cluster\", \"*_index.nii.gz\")))\n",
    "        outputs[\"lga_metrics\"] = [self.get_metrics(f) for f in outputs[\"lga_txt\"]]\n",
    "\n",
    "        return outputs\n",
    "\n",
    "register_workflow(LGAIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PBR interface for running LGA with kappa of increment 0.05__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'sf713420'\n",
    "\n",
    "import os\n",
    "from nipype.interfaces.base import isdefined\n",
    "from utils import doit_workflow, flatten\n",
    "import sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    iter = sys.argv[1]\n",
    "    mse_test = ['mse3727', 'mse4413', 'mse4482', 'mse4739', 'mse4754']\n",
    "    data_ref = [glob('/data/henry7/PBR/subjects/{0}/lst/lga/ms*/*/*_bin_lesion_map.nii'.format(mse)) for mse in mse_test]\n",
    "    data_ref = flatten(data_ref)\n",
    "    print(data_ref,'\\n', len(data_ref))\n",
    "\n",
    "    output_dir = '/data/henry1/tristan/LST/opt_thresh_results/test_subjects'\n",
    "    sk_dir = os.path.join(output_dir)\n",
    "    \n",
    "    if iter == '-iter':\n",
    "        thresh_array = np.linspace(0.05, 1.00, num=20)\n",
    "    elif isdefined(iter):\n",
    "        raise ValueError(\"The option for iterate binary threshold is -iter\")\n",
    "\n",
    "    dwf = doit_workflow(data_ref, thresh_array, sink_dir=sk_dir)\n",
    "    dwf.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This script takes the first positional argument as option for either iterating or not binary threshold for running the LGA DC calculation workflow. __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. New Metric (To Be Continued)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Results\n",
    "\n",
    "### A. Table of Binary Threshold Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Threshold  Dice_Coefficient        SE        SP\n",
      "0        0.05          0.475833  0.358878  0.999789\n",
      "1        0.10          0.468314  0.349578  0.999817\n",
      "2        0.15          0.463385  0.343767  0.999832\n",
      "3        0.20          0.459555  0.339401  0.999842\n",
      "4        0.25          0.456596  0.336025  0.999849\n",
      "5        0.30          0.454107  0.333195  0.999855\n",
      "6        0.35          0.451778  0.330667  0.999859\n",
      "7        0.40          0.449665  0.328433  0.999862\n",
      "8        0.45          0.447638  0.326332  0.999865\n",
      "9        0.50          0.446124  0.324714  0.999868\n",
      "10       0.55          0.444625  0.323119  0.999870\n",
      "11       0.60          0.443311  0.321718  0.999872\n",
      "12       0.65          0.441971  0.320329  0.999874\n",
      "13       0.70          0.440737  0.319028  0.999876\n",
      "14       0.75          0.439719  0.317954  0.999878\n",
      "15       0.80          0.438657  0.316840  0.999879\n",
      "16       0.85          0.437700  0.315826  0.999880\n",
      "17       0.90          0.436781  0.314869  0.999882\n",
      "18       0.95          0.435900  0.313967  0.999882\n",
      "19       1.00          0.435084  0.313113  0.999884\n"
     ]
    }
   ],
   "source": [
    "# from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"/data/henry1/tristan/LST/opt_thresh_results/FLAIR-MPRAGE/averages.csv\")\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Table 1. Averaged Dice Coefficient, SE and SP for all FLAIR-MPRAGE mses with 0.05 increment of binary threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    As is shown in the table, DC decreases with binary threshold increasing. This indicate that the binary threshold has monotonous effect in determining DC. In this case, we will use binary threshold = 0.3 for the later determination of optimal initial threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Table of Initial Threshold Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         FLAIR  kappa        DC        SE       SP\n",
      "0   rmms1624-mse3727-077-FLAIR   0.05  0.551630  0.481400  0.99923\n",
      "1   rmms1624-mse3727-077-FLAIR   0.10  0.533100  0.379960  0.99987\n",
      "2   rmms1624-mse3727-077-FLAIR   0.15  0.462580  0.304510  0.99996\n",
      "3   rmms1624-mse3727-077-FLAIR   0.20  0.395480  0.247350  0.99999\n",
      "4   rmms1624-mse3727-077-FLAIR   0.25  0.338160  0.203700  1.00000\n",
      "5   rmms1624-mse3727-077-FLAIR   0.30  0.312060  0.184990  1.00000\n",
      "6   rmms1624-mse3727-077-FLAIR   0.35  0.269330  0.155680  1.00000\n",
      "7   rmms1624-mse3727-077-FLAIR   0.40  0.248320  0.141760  1.00000\n",
      "8   rmms1624-mse3727-077-FLAIR   0.45  0.233200  0.131990  1.00000\n",
      "9   rmms1624-mse3727-077-FLAIR   0.50  0.206520  0.115150  1.00000\n",
      "10  rmms1624-mse3727-077-FLAIR   0.55  0.196780  0.109120  1.00000\n",
      "11  rmms1624-mse3727-077-FLAIR   0.60  0.192030  0.106210  1.00000\n",
      "12  rmms1624-mse3727-077-FLAIR   0.65  0.178690  0.098109  1.00000\n",
      "13  rmms1624-mse3727-077-FLAIR   0.70  0.164090  0.089379  1.00000\n",
      "14  rmms1624-mse3727-077-FLAIR   0.75  0.147830  0.079817  1.00000\n",
      "15  rmms1624-mse3727-077-FLAIR   0.80  0.109260  0.057784  1.00000\n",
      "16  rmms1624-mse3727-077-FLAIR   0.85  0.018942  0.009561  1.00000\n",
      "17  rmms1624-mse3727-077-FLAIR   0.90  0.009928  0.004989  1.00000\n",
      "18  rmms1624-mse3727-077-FLAIR   0.95  0.000831  0.000416  1.00000\n",
      "19  rmms1624-mse3727-077-FLAIR   1.00  0.000000  0.000000  1.00000\n",
      "20   rmms736-mse4413-010-FLAIR   0.05  0.518860  0.586340  0.99874\n",
      "21   rmms736-mse4413-010-FLAIR   0.10  0.564910  0.484560  0.99957\n",
      "22   rmms736-mse4413-010-FLAIR   0.15  0.523940  0.383210  0.99985\n",
      "23   rmms736-mse4413-010-FLAIR   0.20  0.481540  0.326230  0.99995\n",
      "24   rmms736-mse4413-010-FLAIR   0.25  0.418600  0.266200  0.99999\n",
      "25   rmms736-mse4413-010-FLAIR   0.30  0.384180  0.238800  0.99999\n",
      "26   rmms736-mse4413-010-FLAIR   0.35  0.344830  0.208790  1.00000\n",
      "27   rmms736-mse4413-010-FLAIR   0.40  0.290070  0.169640  1.00000\n",
      "28   rmms736-mse4413-010-FLAIR   0.45  0.245040  0.139630  1.00000\n",
      "29   rmms736-mse4413-010-FLAIR   0.50  0.239660  0.136150  1.00000\n",
      "30   rmms736-mse4413-010-FLAIR   0.55  0.210200  0.117440  1.00000\n",
      "31   rmms736-mse4413-010-FLAIR   0.60  0.177570  0.097434  1.00000\n",
      "32   rmms736-mse4413-010-FLAIR   0.65  0.164470  0.089604  1.00000\n",
      "33   rmms736-mse4413-010-FLAIR   0.70  0.145220  0.078295  1.00000\n",
      "34   rmms736-mse4413-010-FLAIR   0.75  0.114800  0.060896  1.00000\n",
      "35   rmms736-mse4413-010-FLAIR   0.80  0.091324  0.047847  1.00000\n",
      "36   rmms736-mse4413-010-FLAIR   0.85  0.061551  0.031753  1.00000\n",
      "37   rmms736-mse4413-010-FLAIR   0.90  0.046729  0.023923  1.00000\n",
      "38   rmms736-mse4413-010-FLAIR   0.95  0.045068  0.023054  1.00000\n",
      "39   rmms736-mse4413-010-FLAIR   1.00  0.037559  0.019139  1.00000\n",
      "40   rmms870-mse4482-010-FLAIR   0.05  0.745330  0.686420  0.99801\n",
      "41   rmms870-mse4482-010-FLAIR   0.10  0.726020  0.621900  0.99883\n",
      "42   rmms870-mse4482-010-FLAIR   0.15  0.689420  0.557390  0.99924\n",
      "43   rmms870-mse4482-010-FLAIR   0.20  0.646170  0.497680  0.99945\n",
      "44   rmms870-mse4482-010-FLAIR   0.25  0.609110  0.452330  0.99958\n",
      "45   rmms870-mse4482-010-FLAIR   0.30  0.565040  0.404460  0.99965\n",
      "46   rmms870-mse4482-010-FLAIR   0.35  0.521270  0.358480  0.99978\n",
      "47   rmms870-mse4482-010-FLAIR   0.40  0.433960  0.280810  0.99983\n",
      "48   rmms870-mse4482-010-FLAIR   0.45  0.387850  0.242840  0.99988\n",
      "49   rmms870-mse4482-010-FLAIR   0.50  0.346220  0.210980  0.99990\n",
      "50   rmms870-mse4482-010-FLAIR   0.55  0.287110  0.168430  0.99994\n",
      "51   rmms870-mse4482-010-FLAIR   0.60  0.237950  0.135430  0.99996\n",
      "52   rmms870-mse4482-010-FLAIR   0.65  0.166590  0.091049  0.99997\n",
      "53   rmms870-mse4482-010-FLAIR   0.70  0.134310  0.072119  0.99998\n",
      "54   rmms870-mse4482-010-FLAIR   0.75  0.095202  0.050043  0.99998\n",
      "55   rmms870-mse4482-010-FLAIR   0.80  0.073238  0.038033  0.99999\n",
      "56   rmms870-mse4482-010-FLAIR   0.85  0.059675  0.030769  0.99999\n",
      "57   rmms870-mse4482-010-FLAIR   0.90  0.046909  0.024021  1.00000\n",
      "58   rmms870-mse4482-010-FLAIR   0.95  0.041774  0.021333  1.00000\n",
      "59   rmms870-mse4482-010-FLAIR   1.00  0.040677  0.020761  1.00000\n",
      "60   rmms779-mse4739-011-FLAIR   0.05  0.230330  0.544060  0.99940\n",
      "61   rmms779-mse4739-011-FLAIR   0.10  0.311400  0.371650  0.99981\n",
      "62   rmms779-mse4739-011-FLAIR   0.15  0.147470  0.122610  0.99990\n",
      "63   rmms779-mse4739-011-FLAIR   0.20  0.086957  0.065134  0.99992\n",
      "64   rmms779-mse4739-011-FLAIR   0.25  0.034783  0.022989  0.99994\n",
      "65   rmms779-mse4739-011-FLAIR   0.30  0.012308  0.007663  0.99996\n",
      "66   rmms779-mse4739-011-FLAIR   0.35  0.000000  0.000000  0.99997\n",
      "67   rmms779-mse4739-011-FLAIR   0.40  0.000000  0.000000  0.99998\n",
      "68   rmms779-mse4739-011-FLAIR   0.45  0.000000  0.000000  0.99999\n",
      "69   rmms779-mse4739-011-FLAIR   0.50  0.000000  0.000000  0.99999\n",
      "70   rmms779-mse4739-011-FLAIR   0.55  0.000000  0.000000  0.99999\n",
      "71   rmms779-mse4739-011-FLAIR   0.60  0.000000  0.000000  0.99999\n",
      "72   rmms779-mse4739-011-FLAIR   0.65  0.000000  0.000000  1.00000\n",
      "73   rmms779-mse4739-011-FLAIR   0.70  0.000000  0.000000  1.00000\n",
      "74   rmms779-mse4739-011-FLAIR   0.75  0.000000  0.000000  1.00000\n",
      "75   rmms779-mse4739-011-FLAIR   0.80  0.000000  0.000000  1.00000\n",
      "76   rmms779-mse4739-011-FLAIR   0.85  0.000000  0.000000  1.00000\n",
      "77   rmms779-mse4739-011-FLAIR   0.90  0.000000  0.000000  1.00000\n",
      "78   rmms779-mse4739-011-FLAIR   0.95  0.000000  0.000000  1.00000\n",
      "79   rmms779-mse4739-011-FLAIR   1.00  0.000000  0.000000  1.00000\n",
      "80  rmms1206-mse4754-011-FLAIR   0.05  0.710770  0.791500  0.99693\n",
      "81  rmms1206-mse4754-011-FLAIR   0.10  0.747340  0.693460  0.99885\n",
      "82  rmms1206-mse4754-011-FLAIR   0.15  0.721760  0.615050  0.99937\n",
      "83  rmms1206-mse4754-011-FLAIR   0.20  0.677240  0.537130  0.99965\n",
      "84  rmms1206-mse4754-011-FLAIR   0.25  0.629310  0.473020  0.99979\n",
      "85  rmms1206-mse4754-011-FLAIR   0.30  0.581400  0.418780  0.99985\n",
      "86  rmms1206-mse4754-011-FLAIR   0.35  0.547880  0.383470  0.99988\n",
      "87  rmms1206-mse4754-011-FLAIR   0.40  0.504270  0.340570  0.99993\n",
      "88  rmms1206-mse4754-011-FLAIR   0.45  0.467080  0.306830  0.99995\n",
      "89  rmms1206-mse4754-011-FLAIR   0.50  0.420930  0.267780  0.99997\n",
      "90  rmms1206-mse4754-011-FLAIR   0.55  0.366620  0.225070  0.99998\n",
      "91  rmms1206-mse4754-011-FLAIR   0.60  0.317650  0.189070  0.99999\n",
      "92  rmms1206-mse4754-011-FLAIR   0.65  0.276760  0.160670  1.00000\n",
      "93  rmms1206-mse4754-011-FLAIR   0.70  0.246540  0.140650  1.00000\n",
      "94  rmms1206-mse4754-011-FLAIR   0.75  0.222260  0.125060  1.00000\n",
      "95  rmms1206-mse4754-011-FLAIR   0.80  0.201330  0.111940  1.00000\n",
      "96  rmms1206-mse4754-011-FLAIR   0.85  0.185900  0.102480  1.00000\n",
      "97  rmms1206-mse4754-011-FLAIR   0.90  0.172330  0.094289  1.00000\n",
      "98  rmms1206-mse4754-011-FLAIR   0.95  0.156880  0.085117  1.00000\n",
      "99  rmms1206-mse4754-011-FLAIR   1.00  0.149480  0.080777  1.00000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "df2 = pd.read_csv(\"/data/henry1/tristan/LST/opt_thresh_results/test_subjects/_bin_thresh_0.3/For_Jupyter_Display.csv\")\n",
    "print_full(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 2. Initial threshold (kappa) with increment of 0.05 for 5 mse subjects. The DC, SE and SP are displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## IV. Discussion\n",
    "\n",
    "### A. \n",
    "    The threshold in Table 1 is binary threshold for the computation of LGA binary lesion maps, The threshold can be set between 0 to 1, where the thresholding is more liberal when it's set close to 0 and more conservative when it's set close 1. \n",
    "    We concluded from Table 1 the binary threshold has a monotonous effect in determining DC, it will not affect the accuracy of determination of kappa across different subjects as long as binary threshold is kept the same. In this case, binary threshold is set to 0.3 for future determination of optimal initial threshold.\n",
    "\n",
    "### B. \n",
    "    The table in our results displays the outputs of LST’s provided tool for determining the optimal threshold for 5 test subjects iterated over 20 values of kappa (0.05 - 1.0).  Our iteration through various kappa values shows us that the Dice Coefficient is generally inversely proportional to the initial threshold. This implies that a lower kappa value will produce a more accurate lesion map. However, upon inspection of the lesion maps in comparison to manually created and edited lesion maps of the same test subject it appeared that this was not necessarily the case. It is true that we see the least False Negatives in the lesion maps created with the lowest kappa values. However these maps also create False Positives due to their extremely low threshold, and in some cases did not appear to have the most accurate lesion maps. This disparity between the lesion map with the highest Dice Coefficient and the most accurate lesion map calls for a new metric to be used in measuring LGA lesion maps’ accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
